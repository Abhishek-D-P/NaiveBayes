{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19005691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfec534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv('spam_clean.csv',encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af46d",
   "metadata": {},
   "source": [
    "# cleaning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7bab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "import re\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cf5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(sentence):\n",
    "  words=nltk.word_tokenize(sentence)\n",
    "  cleaned_msg=\"\"\n",
    "  for word in words:\n",
    "    word=word.lower()\n",
    "    word=re.sub(r'[^a-z]','',word)\n",
    "    if word!=\"\" and word not in stopwords.words('english'):\n",
    "      cleaned_msg=cleaned_msg+\" \"+word\n",
    "  return cleaned_msg.strip()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c8ba67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "      <th>cleaned_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah nt think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                         cleaned_msg  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry wkly comp win fa cup final tkts st ...  \n",
       "3                u dun say early hor u c already say  \n",
       "4          nah nt think goes usf lives around though  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_msg']=data['message'].apply(clean_message)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe0fb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36d19f",
   "metadata": {},
   "source": [
    "# data preparation for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e046cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.common_words=[]\n",
    "\n",
    "    \n",
    "    def fit(self,X,y,common_words=10):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "\n",
    "        self.prior_prob=self.y.value_counts(normalize=True)\n",
    "        ham=\"\"\n",
    "        spam=\"\"\n",
    "        ham=ham.join(self.X[self.y=='ham'])\n",
    "        ham_words=ham.split()\n",
    "        spam=spam.join(self.X[self.y=='spam'])\n",
    "        spam_words=spam.split()\n",
    "\n",
    "        ham_word_count=np.array(Counter(ham_words).most_common(common_words))[:,0]\n",
    "        spam_word_count=np.array(Counter(spam_words).most_common(common_words))[:,0]\n",
    "\n",
    "        self.features=ham_word_count\n",
    "        self.features=np.append(self.features,spam_word_count)\n",
    "        self.features=np.unique(self.features)\n",
    "        \n",
    "\n",
    "        count_matrix=pd.DataFrame(np.zeros((self.X.shape[0],self.features.shape[0])))\n",
    "        count_matrix.columns=self.features\n",
    "\n",
    "        self.word_frequency_matrix= pd.concat([self.X,count_matrix],axis=1)\n",
    "        self.word_count()\n",
    "        self.word_frequency_matrix.drop(columns='cleaned_msg',inplace=True)\n",
    "\n",
    "        self.word_prob=pd.DataFrame(np.sum(self.word_frequency_matrix)/np.sum(self.word_frequency_matrix).sum(),columns=[\"total\"])\n",
    "        self.word_prob[\"ham\"]=np.sum(self.word_frequency_matrix[self.y==\"ham\"])/np.sum(self.word_frequency_matrix[self.y==\"ham\"]).sum()\n",
    "        self.word_prob[\"spam\"]=np.sum(self.word_frequency_matrix[self.y==\"spam\"])/np.sum(self.word_frequency_matrix[self.y==\"spam\"]).sum()\n",
    "\n",
    "    \n",
    "    def predict(self,query):\n",
    "        # Assuming query is a clean message\n",
    "        words=self.give_me_words_from_features(query)\n",
    "        spam_prob=(np.prod(self.word_prob.loc[words,\"spam\"])*self.prior_prob[\"spam\"]+0.00001)/(np.prod(self.word_prob.loc[words,\"total\"])+2*0.00001)\n",
    "        ham_prob=(np.prod(self.word_prob.loc[words,\"ham\"])*self.prior_prob[\"ham\"]+0.00001)/(np.prod(self.word_prob.loc[words,\"total\"])+2*0.00001)\n",
    "\n",
    "        \n",
    "        return (spam_prob,ham_prob)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    def word_count(self):\n",
    "        for idx,row in enumerate(self.word_frequency_matrix['cleaned_msg']):\n",
    "            word_count=Counter(self.give_me_words_from_features(row))\n",
    "            self.word_frequency_matrix.loc[idx,word_count.keys()]=word_count.values()\n",
    "\n",
    "    def give_me_words_from_features(self,sentence):\n",
    "        return [word for word in sentence.split() if word in self.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a9abd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.48940822520768307, 0.48940822520768307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SONY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\SONY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "NB=NaiveBayes()\n",
    "NB.fit(data['cleaned_msg'],data['type'])\n",
    "print(NB.predict(\"Hi this is a free call , claim ur lt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c822bfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>0.105082</td>\n",
       "      <td>0.061534</td>\n",
       "      <td>0.197183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.020438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>0.050642</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.124507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.070718</td>\n",
       "      <td>0.081779</td>\n",
       "      <td>0.047324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.051185</td>\n",
       "      <td>0.066596</td>\n",
       "      <td>0.018592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>0.045578</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>0.057515</td>\n",
       "      <td>0.084710</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.061534</td>\n",
       "      <td>0.007324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>0.057153</td>\n",
       "      <td>0.084177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile</th>\n",
       "      <td>0.025140</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.069859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nt</th>\n",
       "      <td>0.068186</td>\n",
       "      <td>0.095898</td>\n",
       "      <td>0.009577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply</th>\n",
       "      <td>0.026587</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.058592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.067042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.034364</td>\n",
       "      <td>0.018114</td>\n",
       "      <td>0.068732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.088451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.214686</td>\n",
       "      <td>0.271710</td>\n",
       "      <td>0.094085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>0.069633</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>0.081127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       ham      spam\n",
       "call    0.105082  0.061534  0.197183\n",
       "claim   0.020438  0.000000  0.063662\n",
       "free    0.050642  0.015717  0.124507\n",
       "get     0.070718  0.081779  0.047324\n",
       "go      0.051185  0.066596  0.018592\n",
       "got     0.045578  0.065264  0.003944\n",
       "gt      0.057515  0.084710  0.000000\n",
       "like    0.044131  0.061534  0.007324\n",
       "lt      0.057153  0.084177  0.000000\n",
       "mobile  0.025140  0.003996  0.069859\n",
       "nt      0.068186  0.095898  0.009577\n",
       "reply   0.026587  0.011454  0.058592\n",
       "stop    0.028215  0.009856  0.067042\n",
       "text    0.034364  0.018114  0.068732\n",
       "txt     0.030747  0.003463  0.088451\n",
       "u       0.214686  0.271710  0.094085\n",
       "ur      0.069633  0.064198  0.081127"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c166af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
