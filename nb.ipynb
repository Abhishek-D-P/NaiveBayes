{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19005691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfec534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=pd.read_csv('spam_clean.csv',encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af46d",
   "metadata": {},
   "source": [
    "# cleaning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7bab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SONY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "import re\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cf5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(sentence):\n",
    "  words=nltk.word_tokenize(sentence)\n",
    "  cleaned_msg=\"\"\n",
    "  for word in words:\n",
    "    word=word.lower()\n",
    "    word=re.sub(r'[^a-z]','',word)\n",
    "    if word!=\"\" and word not in stopwords.words('english'):\n",
    "      cleaned_msg=cleaned_msg+\" \"+word\n",
    "  return cleaned_msg.strip()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c8ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_msg']=data['message'].apply(clean_message)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0fb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36d19f",
   "metadata": {},
   "source": [
    "# data preparation for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e046cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.common_words=[]\n",
    "\n",
    "    \n",
    "    def fit(self,X,y,common_words=10):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        ham=\"\"\n",
    "        spam=\"\"\n",
    "        ham=ham.join(self.X[self.y=='ham'])\n",
    "        ham_words=ham.split()\n",
    "        spam=spam.join(self.X[self.y=='spam'])\n",
    "        spam_words=spam.split()\n",
    "\n",
    "        ham_word_count=np.array(Counter(ham_words).most_common(common_words))[:,0]\n",
    "        spam_word_count=np.array(Counter(spam_words).most_common(common_words))[:,0]\n",
    "\n",
    "        self.features=ham_word_count\n",
    "        self.features=np.append(self.features,spam_word_count)\n",
    "        self.features=np.unique(self.features)\n",
    "        \n",
    "\n",
    "        count_matrix=pd.DataFrame(np.zeros((self.X.shape[0],self.features.shape[0])))\n",
    "        count_matrix.columns=self.features\n",
    "\n",
    "        self.word_frequency_matrix= pd.concat([self.X,count_matrix],axis=1)\n",
    "        print(self.word_frequency_matrix.shape)\n",
    "        self.word_count()\n",
    "        return self.word_frequency_matrix\n",
    "    \n",
    "    def word_count(self):\n",
    "        for idx,row in enumerate(self.word_frequency_matrix['cleaned_msg']):\n",
    "            for feature in self.features:\n",
    "                self.word_frequency_matrix.loc[idx,feature]=row.count(feature)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9abd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_msg</th>\n",
       "      <th>call</th>\n",
       "      <th>claim</th>\n",
       "      <th>free</th>\n",
       "      <th>get</th>\n",
       "      <th>go</th>\n",
       "      <th>got</th>\n",
       "      <th>gt</th>\n",
       "      <th>like</th>\n",
       "      <th>lt</th>\n",
       "      <th>mobile</th>\n",
       "      <th>nt</th>\n",
       "      <th>reply</th>\n",
       "      <th>stop</th>\n",
       "      <th>text</th>\n",
       "      <th>txt</th>\n",
       "      <th>u</th>\n",
       "      <th>ur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah nt think goes usf lives around though</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>b going esplanade fr home</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>rofl true name</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_msg  call  claim  free  \\\n",
       "0     go jurong point crazy available bugis n great ...   0.0    0.0   0.0   \n",
       "1                               ok lar joking wif u oni   0.0    0.0   0.0   \n",
       "2     free entry wkly comp win fa cup final tkts st ...   0.0    0.0   1.0   \n",
       "3                   u dun say early hor u c already say   0.0    0.0   0.0   \n",
       "4             nah nt think goes usf lives around though   0.0    0.0   0.0   \n",
       "...                                                 ...   ...    ...   ...   \n",
       "5567  nd time tried contact u u pound prize claim ea...   1.0    1.0   0.0   \n",
       "5568                          b going esplanade fr home   0.0    0.0   0.0   \n",
       "5569                              pity mood suggestions   0.0    0.0   0.0   \n",
       "5570  guy bitching acted like interested buying some...   0.0    0.0   1.0   \n",
       "5571                                     rofl true name   0.0    0.0   0.0   \n",
       "\n",
       "      get   go  got   gt  like   lt  mobile   nt  reply  stop  text  txt    u  \\\n",
       "0     0.0  2.0  1.0  0.0   0.0  0.0     0.0  1.0    0.0   0.0   0.0  0.0  3.0   \n",
       "1     0.0  0.0  0.0  0.0   0.0  0.0     0.0  0.0    0.0   0.0   0.0  0.0  1.0   \n",
       "2     0.0  0.0  0.0  0.0   0.0  0.0     0.0  2.0    0.0   0.0   1.0  1.0  2.0   \n",
       "3     0.0  0.0  0.0  0.0   0.0  0.0     0.0  0.0    0.0   0.0   0.0  0.0  3.0   \n",
       "4     0.0  1.0  0.0  0.0   0.0  0.0     0.0  1.0    0.0   0.0   0.0  0.0  3.0   \n",
       "...   ...  ...  ...  ...   ...  ...     ...  ...    ...   ...   ...  ...  ...   \n",
       "5567  0.0  0.0  0.0  0.0   0.0  0.0     0.0  1.0    0.0   0.0   0.0  0.0  4.0   \n",
       "5568  0.0  1.0  0.0  0.0   0.0  0.0     0.0  0.0    0.0   0.0   0.0  0.0  0.0   \n",
       "5569  0.0  0.0  0.0  0.0   0.0  0.0     0.0  0.0    0.0   0.0   0.0  0.0  1.0   \n",
       "5570  0.0  0.0  0.0  0.0   1.0  0.0     0.0  1.0    0.0   0.0   0.0  0.0  3.0   \n",
       "5571  0.0  0.0  0.0  0.0   0.0  0.0     0.0  0.0    0.0   0.0   0.0  0.0  1.0   \n",
       "\n",
       "       ur  \n",
       "0     1.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "5567  0.0  \n",
       "5568  0.0  \n",
       "5569  0.0  \n",
       "5570  0.0  \n",
       "5571  0.0  \n",
       "\n",
       "[5572 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB=NaiveBayes()\n",
    "NB.fit(data['cleaned_msg'],data['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bfdf0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
